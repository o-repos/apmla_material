
# Advanced Probabilistic Machine Learning and Applications

  Winter semester 2019/2020.
  
  A pdf version containing all this info is Courseinfo.pdf

## Course information
**Lecturers**:  [Isabel Valera](https://ivaleram.github.io/) and [Caterina De Bacco](https://www.cdebacco.com/)

For any general question about the course, use GitHub issues. Before posting, please make sure your question has not been previously answered. Only in case of private question, send us an email. 

**Plan**:  14 Oct 2019 - 9 Feb 2020, 15 weeks, 4hr/week, 15 weeks, 60hr.  

**Lectures**:  Tuesdays 14:15-16pm at TTR2 in Cyber Valley Campus.   

**Tutorials**: Wednesdays 16:15-18pm  at TTR2 in Cyber Valley Campus.   

**Registration**: Register (informally) to the course if you want to receive general course and assignment information via:  https://forms.gle/eqqijGzksdtdbtus8

For the EXAM, NEED to officially register  either via Campus / ALMA or written if the student cannot register online (closer to the exam date).  

**Grading** : Maximum between 70\% written exam+30\% assignments and 100\% exam.   

 1. **1st assignment** (corresponding to Block I) due to December 13th. For questions, contact [Pablo Sanchez](mailto:pablo.sanchez-martin@tuebingen.mpg.de).

	**Submission link:** https://forms.gle/MEfHGXtubda96Jee9 

 2. **2nd assignment** (corresponding to Block II) due to January 17th. For questions, contact [Nicolò Ruggeri](mailto:nicolo.ruggeri@tuebingen.mpg.de) or [Martina Contisciani](mailto:martina.contisciani@tuebingen.mpg.de).

 3. **3rd assignment** (corresponding to Block III) due to February (date to be fixed).

* Every assignment is composed by several exercises, which will be released sequentially before every tutorial session. Information about assignment submission will be provided later in time but it will be made electronically. 

* Assignment may be done and submitted in groups of up to 3 people (optional). 

### Tentative program and schedule

 1.  **Introduction to probabilistic machine learning** (15 Oct ) 
     * _Reference_: Chapter 2 up to Section 2.3.6 and Section 8.2 of Bishop

### BLOCK I:	
2.  **Gaussian Mixture Model (GMM) + Expectation Maximization** (22 Oct) 
    * _Reference_: Section 9.2 of Bishop 
3.  **Bayesian GMM + Gibbs Sampling** (29 Oct)
4.  **DP and infinite Mixture Models (iMMs)** (5 Nov) 
5.  **Temporal point Processes (TPPs) (part I)** (12 Nov) 
6.  **TPPs (part II)+ Sequential Monte Carlo** (19 Nov) 

### BLOCK II:
7.  **Mean Field approach** (26 Nov)
    * _Reference_: AMFM
8.  **TAP approximation** (3 Dec)
    * _Reference_: AMFM
9.  **Bethe Approximation and Belief Propagation part I** (10 Dec)
    * _Reference_: MM  
10. **Bethe Approximation and Belief Propagation part II** (17 Dec)
11. **Spin glass planted (BP) and SBM**  (7 Jan)

### BLOCK III:
12. **GMMs + Variational Inference (VI)** (14 Jan)
13. **VI + LDA** (21 Jan)
14. **Stochastic VI** (28 Jan)
15. **Variational Autoencoders** (4 Feb)
    

### References

* Bishop=C. M. Bishop, _Pattern recognition and machine learning_ (Springer, 2006).
* AMFM=M. Opper and D. Saad, _Advanced mean field methods: Theory and practice_ (MIT press, 2001).
* MM= M. Mèzard and A. Montanari, _Information, Physics and Computation_ (Oxford Graduate texts, 2009).
