
# Advanced Probabilistic Machine Learning and Applications

  Winter semester 2019/2020.
  
  A pdf version containing all this info is Courseinfo.pdf

## Course information
**NEWS**: _confirmed_ date for the 1st exam: **Tuesday March 3rd 2020**, lecture hall in MvL6, 14-16pm.  
**NEWS**: _confirmed_ date for the 2nd exam: **Tuesday April 7th 2020**, lecture hall in MvL6, 14-16pm.   

**NEWS**: No tutorial on Wednesday 28th. Instead, please check the Jupyter notebooks in folder "L14". On the 5th for February, we will go together over the maths and code of the notebooks, answering you any questions you may have.   

**NEWS assignement 3**: There won't be a 3rd assigment but instead we provide you with Jupyter notebooks, with examples of amortized VI and VAE. 

**NEWS assignement 2**: few clarifications about the assignement (following few emails we received):
  1. The parameter `alpha` in the code is not needed, keep it as assigned per default (we introduced it to make initialization more flexible). 
  2. The BP equations should be derived for the question (a), i.e. the uniform probability over the matching size (NOT for the question b)). 
  3. You have the freedom to pick the values of the variables $\sigma_{ij}$, i.e. some discrete values at your choice. Of course, then the compatibility function changes based on this choice. Depending on what you choose, the _Hint_ of question b) may not be needed.  

**Due date** to submit (link to be added) the assignement 1 and 2 of Block II is **January 31st 2020** (submission link below).

**Lecturers**:  [Isabel Valera](https://ivaleram.github.io/) and [Caterina De Bacco](https://www.cdebacco.com/)

For any general question about the course, use GitHub issues. Before posting, please make sure your question has not been previously answered. Only in case of private question, send us an email. 

**Plan**:  14 Oct 2019 - 9 Feb 2020, 15 weeks, 4hr/week, 15 weeks, 60hr.  

**Lectures**:  Tuesdays 14:15-16pm at TTR2 in Cyber Valley Campus.   

**Tutorials**: Wednesdays 16:15-18pm  at TTR2 in Cyber Valley Campus.   

For the EXAM, NEED to officially register  either via Campus / ALMA or written if the student cannot register online (closer to the exam date).  

**Grading** : Maximum between 70\% written exam+30\% assignments and 100\% exam.   

 1. **1st assignment** (corresponding to Block I) due to December 13th. For questions, contact [Pablo Sanchez](mailto:pablo.sanchez-martin@tuebingen.mpg.de).

 2. **2nd assignment** (corresponding to Block II, both 1 and 2) due on **January 31th** (_updated on 11.1.20_). For questions, contact [Nicolò Ruggeri](mailto:nicolo.ruggeri@tuebingen.mpg.de) or [Martina Contisciani](mailto:martina.contisciani@tuebingen.mpg.de).  
  NEWS 1: updated the 7.1.20 the assignement 1 (Block II) with a minor clarification (added the h term inside the TAP equations). The exercise are not changed, this was just to clarify the starting equations. 
  
**Submission Link**: https://forms.gle/CHsqsq8QTGJVJXou7 

_Due date_: Jan 31st 2020

 3. **3rd assignment** (corresponding to Block III) -- It won't be necessary to hand-in any result.  The Jupyter notebooks are already available in folder "L14". "

* Every assignment is composed by several exercises, which will be released sequentially before every tutorial session. Information about assignment submission will be provided later in time but it will be made electronically. 

* Assignment may be done and submitted in groups of up to 3 people (optional). 

### Tentative program and schedule

 1.  **Introduction to probabilistic machine learning** (15 Oct ) 
     * _Reference_: Chapter 2 up to Section 2.3.6 and Section 8.2 of Bishop

### BLOCK I:	
2.  **Gaussian Mixture Model (GMM) + Expectation Maximization** (22 Oct) 
    * _Reference_: Section 9.2 of Bishop 
3.  **Bayesian GMM + Gibbs Sampling** (29 Oct)
4.  **DP and infinite Mixture Models (iMMs)** (5 Nov) 
5.  **Temporal point Processes (TPPs) (part I)** (12 Nov) 
6.  **TPPs (part II)+ Sequential Monte Carlo** (19 Nov) 

### BLOCK II:
7.  **Mean Field approach** (26 Nov)
    * _Reference_: AMFM
8.  **TAP approximation** (3 Dec)
    * _Reference_: AMFM
9.  **Bethe Approximation and Belief Propagation part I** (10 Dec)
    * _Reference_: MM  
10. **Bethe Approximation and Belief Propagation part II** (17 Dec)
11. **SBM**  (7 Jan)

### BLOCK III:
12. **GMMs + Variational Inference (VI)** (14 Jan)
13. **VI + LDA** (21 Jan)
14. **Advanced VI (part I): Stochastic VI and Black Box VI** (28 Jan)
15. **Advanced VI (part II): Amortized Inference and Variational Autoencoders** (4 Feb)
    

### References

* Bishop=C. M. Bishop, _Pattern recognition and machine learning_ (Springer, 2006).
* AMFM=M. Opper and D. Saad, _Advanced mean field methods: Theory and practice_ (MIT press, 2001).
* MM= M. Mèzard and A. Montanari, _Information, Physics and Computation_ (Oxford Graduate texts, 2009).
